{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Student-Model\" data-toc-modified-id=\"Student-Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Student Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-processing\" data-toc-modified-id=\"Data-processing-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data processing</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-Model\" data-toc-modified-id=\"Define-Model-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Define Model</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Train</a></span></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#ROC-AUC\" data-toc-modified-id=\"ROC-AUC-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>ROC AUC</a></span></li><li><span><a href=\"#Compression-rate\" data-toc-modified-id=\"Compression-rate-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Compression rate</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Model\n",
    "\n",
    "\n",
    "Нужно обучть небольшую модель на [soft таргетах](https://drive.google.com/file/d/1tBbPOUT-Ow9f3zTDApykGXYwt-KslYle/view?usp=sharing)  модели учителя, которая не сильно уступала бы в качестве учителю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/criteo'\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "SOFT_TARGETS_PATH = os.path.join(DATA_PATH, 'soft_targets_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Данные на Train/Validation/Test нужно разбить как 80/10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, islice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [f'_c{i}' for i in range(1, 14)]\n",
    "cat_features = [f'_c{i}' for i in range(14, 40)]\n",
    "\n",
    "cat_features_dims = dict([\n",
    "    ('c14', 1445),\n",
    "    ('c15', 556),\n",
    "    ('c16', 1130758),\n",
    "    ('c17', 360209),\n",
    "    ('c18', 304),\n",
    "    ('c19', 21),\n",
    "    ('c20', 11845),\n",
    "    ('c21', 631),\n",
    "    ('c22', 3),\n",
    "    ('c23', 49223),\n",
    "    ('c24', 5194),\n",
    "    ('c25', 985420),\n",
    "    ('c26', 3157),\n",
    "    ('c27', 26),\n",
    "    ('c28', 11588),\n",
    "    ('c29', 715441),\n",
    "    ('c30', 10),\n",
    "    ('c31', 4681),\n",
    "    ('c32', 2029),\n",
    "    ('c33', 4),\n",
    "    ('c34', 870796),\n",
    "    ('c35', 17),\n",
    "    ('c36', 15),\n",
    "    ('c37', 87605),\n",
    "    ('c38', 84),\n",
    "    ('c39', 58187)])\n",
    "\n",
    "\n",
    "MAX_DICT_SIZE = 10000\n",
    "\n",
    "\n",
    "label_features = [feature for feature, cardinality in cat_features_dims.items() if cardinality <= MAX_DICT_SIZE]\n",
    "hash_features = [feature for feature, cardinality in cat_features_dims.items() if cardinality > MAX_DICT_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "soft_targets = pd.read_csv(SOFT_TARGETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder = Pipeline([\n",
    "    ('fill', SimpleImputer(missing_values=np.nan, strategy='mean')), \n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_encoder = Pipeline([\n",
    "    ('fill', SimpleImputer(missing_values=np.nan, strategy='constant')),\n",
    "    ('ord', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "data_transformer = ColumnTransformer([\n",
    "    ('num_encoder', num_encoder, num_features), \n",
    "    ('cat_encoder', cat_encoder, cat_features)\n",
    "])\n",
    "\n",
    "x = data_transformer.fit_transform(data).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['_c0'].values\n",
    "soft_targets = soft_targets['prob'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_tv, y_train, y_tv, soft_targets_train, soft_targets_tv = train_test_split(x, y, soft_targets, train_size=.8)\n",
    "x_val, x_test, y_val, y_test, soft_targets_val, soft_targets_test = \\\n",
    "    train_test_split(x_tv, y_tv, soft_targets_tv, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, x, y, soft_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Можно также использовать Pruning и/или Quantinization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossModule(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(CrossModule, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.w = nn.Parameter(torch.FloatTensor(dim))\n",
    "        self.b = nn.Parameter(torch.FloatTensor(dim))\n",
    "        nn.init.normal_(self.w, std=1 / dim)\n",
    "        nn.init.normal_(self.b, std=1 / dim)\n",
    "        \n",
    "    def forward(self, x0, x_prev):\n",
    "        return x0.reshape(-1, self.dim, 1) @ x_prev.reshape(-1, 1, self.dim) @ self.w + self.b + x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_emb_dim(vocab_size):\n",
    "    return int(4 * vocab_size ** 0.25)\n",
    "\n",
    "\n",
    "class HashEmbedding(nn.Module):\n",
    "    #  Используется тривиальная хеш-функция\n",
    "    #  Для больших словарей деление на максимальный размер словаря используется в качестве второго хеша\n",
    "    #  Ожидается, что размер словаря не превосходит квадрат ограничения на словарь эмбеддинга\n",
    "    def __init__(self, vocab_size, emb_vocab_size):\n",
    "        super(HashEmbedding, self).__init__()\n",
    "        self.emb_vocab_size = emb_vocab_size\n",
    "        emb1_dim = min(vocab_size, emb_vocab_size)\n",
    "        self.emb1 = nn.Embedding(emb1_dim, calc_emb_dim(emb1_dim))\n",
    "        if vocab_size > emb_vocab_size:\n",
    "            emb2_dim = vocab_size // emb_vocab_size + 1\n",
    "            self.emb2 = nn.Embedding(emb2_dim, calc_emb_dim(emb2_dim))\n",
    "            self.out_dim = calc_emb_dim(emb1_dim) + calc_emb_dim(emb2_dim)\n",
    "        else:\n",
    "            self.emb2 = None\n",
    "            self.out_dim = calc_emb_dim(emb1_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.emb2:\n",
    "            return torch.cat((self.emb1(x % self.emb_vocab_size), self.emb2(x // self.emb_vocab_size)), axis=1)\n",
    "        return self.emb1(x % self.emb_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, num_dim, cat_vocabs, max_vocab, cross_layers, deep_layers, deep_dim):\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.max_vocab = max_vocab\n",
    "        self.embeddings = nn.ModuleList(HashEmbedding(vocab_size, max_vocab) for vocab_size in cat_vocabs)\n",
    "        \n",
    "        self.num_dim = num_dim\n",
    "        self.n_cat_features = len(cat_vocabs)\n",
    "        data_dim = num_dim + sum(emb.out_dim for emb in self.embeddings)\n",
    "        \n",
    "        self.cross = nn.ModuleList(CrossModule(data_dim) for _ in range(cross_layers))\n",
    "        self.deep = nn.Sequential(\n",
    "            nn.Linear(data_dim, deep_dim), nn.ReLU(),\n",
    "            *chain(*((nn.Linear(deep_dim, deep_dim), nn.ReLU()) for _ in range(deep_layers - 1)))\n",
    "        )\n",
    "        self.final = nn.Linear(data_dim + deep_dim, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        num_part = x[:, :self.num_dim]\n",
    "        cat_part = [x[:, i].long() % self.max_vocab for i in range(self.num_dim, self.num_dim + self.n_cat_features)]\n",
    "        cat_part = [x[:, i].long() for i in range(self.num_dim, self.num_dim + self.n_cat_features)]\n",
    "        emb_features = [emb(cats) for emb, cats in zip(self.embeddings, cat_part)]\n",
    "        embedded_batch = torch.cat([num_part, *emb_features], dim=1)\n",
    "        cross_out = self.cross[0](embedded_batch, embedded_batch)\n",
    "        for cross_layer in self.cross[1:]:\n",
    "            cross_out = cross_layer(embedded_batch, cross_out)\n",
    "        deep_out = self.deep(embedded_batch)\n",
    "        out = self.final(torch.cat([cross_out, deep_out], dim=1))\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedDataset:\n",
    "    def __init__(self, batch_size, *args):\n",
    "        self.batch_size = batch_size\n",
    "        self.data_streams = args\n",
    "        self.size = len(args[0])\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_start in range(0, self.size, self.batch_size):\n",
    "            yield (torch.tensor(i[batch_start:batch_start + self.batch_size]) for i in self.data_streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_dataset = BatchedDataset(BATCH_SIZE, x_train, y_train, soft_targets_train)\n",
    "val_dataset = BatchedDataset(BATCH_SIZE, x_val, y_val, soft_targets_val)\n",
    "test_dataset = BatchedDataset(BATCH_SIZE, x_test, y_test, soft_targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "distillation_loss_weight = torch.tensor(.8).cuda()\n",
    "pred_loss_weight = torch.tensor(1.).cuda() - distillation_loss_weight\n",
    "\n",
    "\n",
    "def train(model, n_epochs, train_dataset, val_dataset):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "    loss_func = nn.BCELoss()\n",
    "    \n",
    "    def get_loss():\n",
    "        return loss_func(pred, soft_target_batch) * distillation_loss_weight + \\\n",
    "                loss_func(pred, y_batch.float()) * pred_loss_weight\n",
    "    \n",
    "    model = model.cuda()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_losses, val_losses, val_aucs = [], [], []\n",
    "        for x_batch, y_batch, soft_target_batch in tqdm(train_dataset):\n",
    "            x_batch, y_batch, soft_target_batch = x_batch.cuda(), y_batch.cuda(), soft_target_batch.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x_batch).flatten()\n",
    "            loss = get_loss()\n",
    "            cur_loss = loss.cpu().detach().numpy()\n",
    "            train_losses.append(cur_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = np.mean(train_losses)\n",
    "        \n",
    "        for x_batch, y_batch, soft_target_batch in val_dataset:\n",
    "            x_batch, y_batch, soft_target_batch = x_batch.cuda(), y_batch.cuda(), soft_target_batch.cuda()\n",
    "            pred = model(x_batch).flatten()\n",
    "            loss = get_loss()\n",
    "            val_losses.append(loss.cpu().detach().numpy())\n",
    "            val_aucs.append(roc_auc_score(y_batch.cpu().numpy(), pred.cpu().detach().numpy()))\n",
    "        val_loss = np.mean(val_losses)\n",
    "        val_auc = np.mean(val_aucs)\n",
    "        \n",
    "        print(f'Epoch {epoch}: train loss = {train_loss}, val loss = {val_loss}, val auc = {val_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11453it [27:09,  7.03it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss = 0.4879852831363678, val loss = 0.4566759169101715, val auc = 0.7766140730814006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11453it [27:06,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 0.47401997447013855, val loss = 0.4486025273799896, val auc = 0.7834970444593512\n"
     ]
    }
   ],
   "source": [
    "model = StudentNet(13, cat_features_dims.values(), 5000, 3, 3, 128)\n",
    "train(model, 2, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Наша основная задача получить модель, которая \n",
    "* в терминах ROC AUC не намного хуже модели учителя, и в то же время \n",
    "* сильно меньше по размеру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC\n",
    "\n",
    "Сравним ROC AUC модели ученика с показателем для учителя.\n",
    "\n",
    "ROC AUC учителя: 0.802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = [model(x_batch.cuda()).detach().cpu().numpy() for x_batch, _, _ in test_dataset]\n",
    "test_preds = np.concatenate(test_preds).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7823543453206878"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression rate\n",
    "\n",
    "Пусть \n",
    "* $a$ - \\# of the parameters in the original model $M$\n",
    "* $a^{*}$ - \\# of the parameters in compressed model $M^{*}$\n",
    "\n",
    "тогда compression rate is $$\\alpha(M,M^{*}) = \\frac{a}{a^{*}}$$\n",
    "\n",
    "Можно также посчитать comression rate просто как отношение фактических размеров моделей.\n",
    "\n",
    "Размер модели учителя - 168MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.856290817260742"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = 'model.pt'\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "model_size = Path(MODEL_PATH).stat().st_size / (2 ** 10 * 2 ** 10)\n",
    "model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.969566770839457"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_rate = 168 / model_size\n",
    "compression_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
